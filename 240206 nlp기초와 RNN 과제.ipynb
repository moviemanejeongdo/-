{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 2s 0us/step\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7171 - val_loss: 0.3909 - val_accuracy: 0.8370\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.3116 - accuracy: 0.8752 - val_loss: 0.3329 - val_accuracy: 0.8530\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.2344 - accuracy: 0.9107 - val_loss: 0.3293 - val_accuracy: 0.8550\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.1861 - accuracy: 0.9334 - val_loss: 0.3389 - val_accuracy: 0.8534\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.1462 - accuracy: 0.9556 - val_loss: 0.3553 - val_accuracy: 0.8496\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.1123 - accuracy: 0.9696 - val_loss: 0.3802 - val_accuracy: 0.8434\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.0821 - accuracy: 0.9827 - val_loss: 0.4016 - val_accuracy: 0.8432\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.0581 - accuracy: 0.9906 - val_loss: 0.4254 - val_accuracy: 0.8424\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.0400 - accuracy: 0.9961 - val_loss: 0.4528 - val_accuracy: 0.8416\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.0269 - accuracy: 0.9987 - val_loss: 0.4868 - val_accuracy: 0.8370\n",
      "782/782 [==============================] - 1s 817us/step - loss: 0.4926 - accuracy: 0.8338\n",
      "Test Accuracy: 0.833840012550354\n"
     ]
    }
   ],
   "source": [
    "# Q1_0206.imdb 영화 리뷰 데이터셋을 사용하여 긍부정 이진분류 모델링 및 평가를 수행하세요\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "# 데이터셋 로드\n",
    "# num_words=10000은 훈련 데이터에서 가장 자주 나타나는 상위 10,000개의 단어만 사용하겠다는 의미입니다.\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# 시퀀스 데이터 패딩\n",
    "x_train = pad_sequences(x_train, maxlen=100)   #패딩은 시퀀스(여기서는 텍스트 데이터의 각 문장을 나타내는 정수 시퀀스)의 길이를 동일하게 맞추는 작업입니다. 이는 일반적으로 신경망 모델에 입력 데이터를 공급하기 전에 필요한 전처리 단계입니다.\n",
    "x_test = pad_sequences(x_test, maxlen=100)\n",
    "\n",
    "# 첫 번째 매개변수: 패딩을 적용할 시퀀스 데이터입니다. 여기서는 x_train 또는 x_test입니다.\n",
    "# maxlen: 시퀀스의 최대 길이를 지정합니다. 이 값은 모든 시퀀스가 가질 길이를 의미합니다. maxlen보다 긴 시퀀스는 잘려나가고, 짧은 시퀀스는 maxlen에 도달할 때까지 패딩(기본적으로 0)이 추가됩니다. 여기서는 maxlen=100으로 설정되어 있어, 모든 리뷰 시퀀스의 길이를 100으로 맞춥니다.\n",
    "\n",
    "# 모델 구성\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 8, input_length=100))  # Embedding 레이어 추가\n",
    "model.add(Flatten())  # 평탄화 레이어 추가\n",
    "model.add(Dense(1, activation='sigmoid'))  # 출력 레이어 추가 (시그모이드 활성화 함수 사용)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('Test Accuracy:', test_acc)\n",
    "\n",
    "\n",
    "# 이 코드에서 긍정과 부정을 나타내는 부분은 `y_train`과 `y_test`에 포함되어 있습니다. \n",
    "# `imdb.load_data(num_words=10000)` 함수로 로드된 `y_train`과 `y_test`는 각각 훈련 세트와 테스트 세트의 레이블(타겟)을 담고 있습니다.\n",
    "\n",
    "# IMDB 데이터셋에서 각 리뷰는 긍정적인 리뷰인 경우 1, 부정적인 리뷰인 경우 0으로 레이블링되어 있습니다. 따라서, 이 레이블들은 모델이 예측해야 할 타겟(목표)입니다.\n",
    "\n",
    "# 모델 구성 부분에서 `Dense(1, activation='sigmoid')`는 하나의 출력 유닛(노드)과 시그모이드 활성화 함수를 사용하는 출력 레이어를 추가합니다. \n",
    "# 시그모이드 함수는 출력 값을 0과 1 사이로 제한합니다. 이는 이진 분류 문제에 적합하며, 모델의 출력은 리뷰가 긍정적(1에 가까움)인지 부정적(0에 가까움)인지를 나타내는 확률로 해석할 수 있습니다.\n",
    "\n",
    "# 모델이 훈련되면, `model.fit` 함수는 `x_train`에 있는 리뷰 데이터와 `y_train`에 있는 레이블을 사용하여 모델을 학습시킵니다. \n",
    "# 이후 `model.evaluate` 함수는 `x_test`와 `y_test`를 사용하여 테스트 데이터에 대한 모델의 성능을 평가합니다. \n",
    "# 여기서 `test_acc`는 모델이 테스트 데이터에서 얼마나 정확하게 긍정 또는 부정 리뷰를 분류하는지를 나타내는 정확도입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 훈련 시퀀스\n",
      "25000 테스트 시퀀스\n",
      "input_train 크기: (25000, 100)\n",
      "input_test 크기: (25000, 100)\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.5799 - acc: 0.6762 - val_loss: 0.4154 - val_acc: 0.8186\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.3674 - acc: 0.8443 - val_loss: 0.4040 - val_acc: 0.8136\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.3103 - acc: 0.8734 - val_loss: 0.3629 - val_acc: 0.8384\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 0.2792 - acc: 0.8890 - val_loss: 0.3735 - val_acc: 0.8454\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.2585 - acc: 0.9014 - val_loss: 0.3618 - val_acc: 0.8442\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 0.2343 - acc: 0.9086 - val_loss: 0.3888 - val_acc: 0.8420\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 0.2177 - acc: 0.9187 - val_loss: 0.4460 - val_acc: 0.8374\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 0.1924 - acc: 0.9301 - val_loss: 0.4276 - val_acc: 0.8198\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 0.1692 - acc: 0.9365 - val_loss: 0.4440 - val_acc: 0.8308\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 0.1475 - acc: 0.9453 - val_loss: 0.5053 - val_acc: 0.8254\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 100\n",
    "\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(input_train), '훈련 시퀀스')\n",
    "print(len(input_test), '테스트 시퀀스')\n",
    "\n",
    "#시퀀스패딩\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "\n",
    "print('input_train 크기:', input_train.shape)\n",
    "print('input_test 크기:', input_test.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 8, input_length=100))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(input_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 22/625 [>.............................] - ETA: 4s - loss: 0.0540 - acc: 0.9801"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 5s 8ms/step - loss: 0.0669 - acc: 0.9765 - val_loss: 0.6775 - val_acc: 0.7782\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.0559 - acc: 0.9816 - val_loss: 0.7515 - val_acc: 0.8056\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 0.0503 - acc: 0.9837 - val_loss: 0.8471 - val_acc: 0.7962\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 0.0386 - acc: 0.9871 - val_loss: 0.8857 - val_acc: 0.7796\n"
     ]
    }
   ],
   "source": [
    "# Q2_0206. IMDB 영화 리뷰 데이터셋에 대한 감성 분석을 수행하는 SimpleRNN 모델을 구성하고 훈련하는 예제에 EarlyStopping과 ModelCheckpoint 콜백을 추가하여 모델 훈련을 개선하세요\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# EarlyStopping 콜백 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# ModelCheckpoint 콜백 설정\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras', \n",
    "    monitor='val_loss', \n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(\n",
    "    input_train, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 116ms/step\n",
      "리뷰: sent to paris to learn something so what exactly do they learn when they meet two french boys and are able to manipulate the guy that supposed to watch them so they can meet these guys on ? the typical pre teen movie having all pre teens wishing to and be able to afford the trip to paris or some far away country away from parents i dont really like the anyways they never could really shake off the image of michelle on full house in case you didnt see that then you were lucky from the start f f\n",
      "실제 레이블: 부정\n",
      "예측된 레이블: 긍정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "리뷰: quite enjoyed this remake with all these horror remakes floating about i think this is one of the better attempts br br i watched it with my two little sisters and i think it made it even better as they were quite scared also with the shouting at the screen dont do that not that way etc i thought there were some good little ? moments and it built the tension well br br ? belle is absolutely stunning in the lead role and a very good actress so she holds your attention well br br overall a decent film\n",
      "실제 레이블: 긍정\n",
      "예측된 레이블: 긍정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "리뷰: uncle to lift the curse comic hilarity ensues this movie has the same snakes over and over it has garden snakes and ? that will never bite they all make the sound of ? which makes no sense the whole movie has some funny lines some weak effects but most important a great ending that leaves you like ? ? what the heck just happened the whole movie is about a 1 but the ending is a 10 so by my crazy ? it gets a 3 overall when blockbuster has nothing else you want grab this for mindless entertainment\n",
      "실제 레이블: 부정\n",
      "예측된 레이블: 긍정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "리뷰: it's mutual secondly there is a long standing problem in his marriage that is brought to light when an old friend of both his and his wife becomes ill the consequences of the wife's involvement with this friend both past and present are almost too sad to bear br br nothing is treated in this film all the characters have a vivid internal life and an easily discernible history the two leads ? cheung and anita are outstanding as are ? as the student ? ? and shaun ? as the elder son on ? br br recommended without ?\n",
      "실제 레이블: 긍정\n",
      "예측된 레이블: 긍정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "리뷰: events and contemporary problems in but not only the whole world the ethnic ? is such a huge evil and very nowadays so children of wax or as it is known in us distribution reveals the question of german and hatred in an amusing way no doubt it is well appreciated to be taken for distribution by the great brothers and there is another fact i liked most is the participation in this movie of the favorite actor of lars von trier the great ? ? who shows to play with such a pleasure for the ? film director ?\n",
      "실제 레이블: 긍정\n",
      "예측된 레이블: 긍정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "리뷰: movie and know that viewers will see and learn things they didn't know before this movie is truly one of a kind it's hard to ? because it has pieces of sci fi and suspense and also how to make a movie it tells the truth about how films get made what can go wrong and how to overcome i especially liked the music written by ed these guys know how to produce a good movie on a shoe string because they're creative and know how to build props ? staging lighting with what they can up pretty amazing stuff\n",
      "실제 레이블: 긍정\n",
      "예측된 레이블: 긍정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "리뷰:  even if it has a downbeat follow up another definite asset is the film's sparse score  which is generally rather lovely but becoming unnerving at just the right moments br br at the end of the day black water emerges as a breath of fresh air in the face of the ? into which horror cinema has fallen of late for this reason alone it deserves greater exposure so as to remind us that there's hope yet for our beloved genre without the real necessity of ? to the ? of a ? 2008 to command attention \n",
      "실제 레이블: 긍정\n",
      "예측된 레이블: 긍정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "리뷰: help either the artist and or title of song thanks mike this is for all you movie buffs lets see if you know your stuff br br hi i have been looking 4 the soundtrack or a song from the film does anyone know who sung the title song i think it was called welcome home or coming home br br it is played throughout the film and for the end credits please can anyone help either the artist and or title of song thanks mike this is for all you movie buffs lets see if you know your stuff\n",
      "실제 레이블: 긍정\n",
      "예측된 레이블: 긍정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "리뷰: and very good filming but ? beat out ? in four ways in my opinion first the characters were more unique in ? the music was better in ? the idea was original in ? unlike ? ? and the biggest difference the action sequences oh my gosh ? was a western with really good action sequences i mean really good the action was fast paced like modern day based ? up movies the action had big budget explosions too the ? were pretty good also mario van ? was great in this movie i suggest buying this excellent movie\n",
      "실제 레이블: 긍정\n",
      "예측된 레이블: 긍정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "리뷰: ? ? ? ? ? ? ? ? ? ? ? ? as a czech i am very pleased when i read these comments here i am absolutely sure that this film is great and what you maybe don't know is that story was specially written for mr the man you can see is him and his typical attitude to live and to resist death he was one of great actors and we are very lucky that we he has made so many beautiful films during his life you are lucky you could see at least one of them enjoy\n",
      "실제 레이블: 긍정\n",
      "예측된 레이블: 긍정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "리뷰: be in horrible taste but has really gained a cult following world wide says a lot about us us being people doesn't it pink ? succeeds because waters made the film he wanted to make a film need not be disgusting to succeed but it may be when you watch this film you see things that are disgusting but are ultimately brilliant because they are ? displayed what we have here is an honest piece of personal creative expression everyone who ever cares to succeed as an artist be it in film or any other media should watch this film\n",
      "실제 레이블: 긍정\n",
      "예측된 레이블: 부정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "리뷰: and comic timing she being the best thing in this movie the wilder gags were flat and frankly more like something a ? in college would write trying to get away w being wicked witty and dirty but just sounded boring and not funny at all it seemed the humor was being pushed too hard to be funny the ending was totally contrived br br spoiler ahead never for a moment did i believe that art ? suddenly fell outta love w ? and then was suddenly ? in love w arthur oh billy get real 3 out of 10\n",
      "실제 레이블: 부정\n",
      "예측된 레이블: 긍정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "리뷰: it comes to penguin but he is good and memorable br br keaton is underrated as batman br br and the music and style are pure cinema thrill true the 3rd act doesn't work but the final 2 scenes are ? and it's clear pfeiffer and keaton were meant to be in a trilogy that got ? by this film's kinky darkness that's too bad because ? and keaton had classic chemistry and had they acted in a third installment joel you know who might not have gotten the chance to destroy batman for an entire generation of movie fans\n",
      "실제 레이블: 긍정\n",
      "예측된 레이블: 긍정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "리뷰: chemistry br br a film that doesn't know what it is made without any love to some mysterious end that leaves you depressed and feeling kind of angry that so much money was wasted br br the ? obviously were made an offer they couldn't refuse or perhaps their ? have simply got the better of them it's a bleak marketing push that perhaps would have been better when the ? were ? and more inspired br br i however did know when to stop and did br br please someone try to convince me of this film's ? points\n",
      "실제 레이블: 부정\n",
      "예측된 레이블: 부정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "리뷰: ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? i have seen this play many times from olivier to branagh and this remains the one version that always stands out in my memory many actors have captured aspects of this character but for me it is always derek ? performance they are compared to and all others just come up a bit short\n",
      "실제 레이블: 긍정\n",
      "예측된 레이블: 긍정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "리뷰: even startling i went to see it with a bunch of friends and by the end of the night we were saying the ruins ruined my night br br i would not recommend seeing this movie in theaters renting it or even watching the movie on television by accident it is an absolute waste of an hour and a half br br the plot was nearly non existent the characters were horribly underdeveloped and they gave no back story whatsoever for anything that was happening and then left it completely open at the end as if preparing for a sequel\n",
      "실제 레이블: 부정\n",
      "예측된 레이블: 부정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "리뷰: may find some scenes hard going but the thing is far from being simply a horror classic the fact that the extraordinary special effects stand up against most modern day cgi is only a small part of why this movie is finally rightfully regarded as a masterpiece technically brilliant in its camera work and editing superbly scripted and acted one of the best ? one of the best endings tension and paranoia ? throughout with countless viewings an excellent soundtrack and open to multiple ? and ? there simply aren't enough ? to do this film justice absolutely essential viewing\n",
      "실제 레이블: 긍정\n",
      "예측된 레이블: 긍정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "리뷰: that really should have been edited down to something closer to 2 hours it's almost 3 hours br br we follow the lives of 3 men from 1938 through the end of wwii and watch as they discover who they are and what they might become as they discover both the world about them and what they're made of for some it's the women in their lives that brings about this realization for others it's the ? general circumstances all too often however i found myself asking what had just happened or what the ? of a particular scene was\n",
      "실제 레이블: 부정\n",
      "예측된 레이블: 긍정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "리뷰: old really fast i saw this film last night in france we are in the valley which is covered with and of course wine makers they were all there in the ? de for the showing ? in polite patient ? although my french is ? i got the ? of the film but noted that the audience loved the old terror ? interviewed ? the one from a communist village in he got a lot of laughs this is unusual in france laughing ? there is no question which side of the terror ? war they are on ?\n",
      "실제 레이블: 긍정\n",
      "예측된 레이블: 긍정\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "리뷰: white with a voice over sets the pace for the entire rest of the film the fight scenes look ridiculous the ? would be funny if the acting wasn't so bad what passes for plot doesn't make sense and the production values bite from the knock off of ? coat worn by the hero to the cheesy cheap ? cape their lead ? ? around br br i've seen some bad movies check out the magic sword with b ? or the ? with a very young jack n but this one gets my vote for worst of all times\n",
      "실제 레이블: 부정\n",
      "예측된 레이블: 부정\n",
      "\n",
      "\n",
      "선택된 20개 샘플의 정확도: 0.75\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "# 저장된 모델 로드\n",
    "model = load_model('best_model.keras')\n",
    "\n",
    "# IMDB 데이터셋의 단어 인덱스 로드\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# 텍스트를 디코딩하는 함수\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in text])\n",
    "\n",
    "# 테스트 데이터셋에서 20개 샘플 무작위 선택\n",
    "indices = np.random.randint(0, len(input_test), size=20)\n",
    "\n",
    "correct_predictions = 0\n",
    "\n",
    "for i in indices:\n",
    "    review = decode_review(input_test[i])\n",
    "    true_label = y_test[i]\n",
    "    prediction = model.predict(np.array([input_test[i]]))[0][0]\n",
    "    predicted_label = 1 if prediction > 0.5 else 0\n",
    "\n",
    "    if predicted_label == true_label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "    print(\"리뷰:\", review)\n",
    "    print(\"실제 레이블:\", '긍정' if true_label else '부정')\n",
    "    print(\"예측된 레이블:\", '긍정' if prediction > 0.5 else '부정')\n",
    "    print(\"\\n\")\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = correct_predictions / 20\n",
    "print(\"선택된 20개 샘플의 정확도:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
