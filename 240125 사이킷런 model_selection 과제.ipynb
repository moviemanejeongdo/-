{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# Q. 타이타닉 생존자 예측 데이터 세트 train.csv에 대하여 다음 사항을 수행하세요.\n",
    "# - 일괄 전처리 사용자 함수 transform_features(df) 작성\n",
    "\n",
    "# - 1. dt, lr, rf 모델링 및 평가(정확도)\n",
    "\n",
    "# - 2. dt_clf , folds=5 적용하여 KFold 교차검증 수행\n",
    "\n",
    "# - 3. dt_clf , cv=5 적용, cross_val_score를 이용하여 교차검증 수행\n",
    "\n",
    "# - 4. GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행.\n",
    "#   - parameters = {'max_depth':[2,3,5,10], 'min_samples_split':[2,3,5], 'min_samples_leaf':[1,5,8]}\n",
    "#   - dt_clf, scoring='accuracy', cv=5 적용\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "print(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - 정확도: 0.7877, 정밀도: 0.6885, 재현율: 0.6885\n",
      "Logistic Regression - 정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n",
      "Random Forest - 정확도: 0.8547, 정밀도: 0.8070, 재현율: 0.7541\n"
     ]
    }
   ],
   "source": [
    "# - 1. dt, lr, rf 모델링 및 평가(정확도)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#결측치 Null 처리, age는 평균, cabin 은 null, embarked null, fare 0\n",
    "\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "#머신러닝 알고리즘에 불필요한 속성 제거, passengerid, name, ticket\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis = 1, inplace=True)\n",
    "    return df\n",
    "\n",
    "#레이블 인코딩 수행 cabin 선실번호 첫문자만 추출 후 인코딩, sex, embarked 사용\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 사용자 함수 한번에 실행\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df\n",
    "\n",
    "# 타이타닉 데이터셋 로드 및 전처리\n",
    "titanic_df = pd.read_csv('train.csv')\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "\n",
    "# 위에서 설정한 사용자 함수 실행\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)\n",
    "\n",
    "# 모델 생성 및 평가 함수\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "# 결정 트리, 로지스틱 회귀, 랜덤 포레스트 모델 생성 및 평가\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "lr_clf = LogisticRegression()\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "\n",
    "dt_accuracy, dt_precision, dt_recall = evaluate_model(dt_clf, X_train, X_test, y_train, y_test)\n",
    "lr_accuracy, lr_precision, lr_recall = evaluate_model(lr_clf, X_train, X_test, y_train, y_test)\n",
    "rf_accuracy, rf_precision, rf_recall = evaluate_model(rf_clf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 평가 결과 출력\n",
    "print(\"Decision Tree - 정확도: {:.4f}, 정밀도: {:.4f}, 재현율: {:.4f}\".format(dt_accuracy, dt_precision, dt_recall))\n",
    "print(\"Logistic Regression - 정확도: {:.4f}, 정밀도: {:.4f}, 재현율: {:.4f}\".format(lr_accuracy, lr_precision, lr_recall))\n",
    "print(\"Random Forest - 정확도: {:.4f}, 정밀도: {:.4f}, 재현율: {:.4f}\".format(rf_accuracy, rf_precision, rf_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정 트리 kfold=5 교차 검증의 평균 정확도: 0.7823\n"
     ]
    }
   ],
   "source": [
    "# - 2. dt_clf , folds=5 적용하여 KFold 교차검증 수행\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "# 결정 트리 분류기\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "\n",
    "# KFold 교차 검증 수행\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = cross_val_score(dt_clf, X_titanic_df, y_titanic_df, cv=kfold)\n",
    "\n",
    "# 평균 정확도 계산\n",
    "mean_accuracy = np.mean(cv_accuracy)\n",
    "\n",
    "print(f'결정 트리 kfold=5 교차 검증의 평균 정확도: {mean_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정 트리 cross_val_score 검증의 평균 정확도: 0.7879\n"
     ]
    }
   ],
   "source": [
    "# - 3. dt_clf , cv=5 적용, cross_val_score를 이용하여 교차검증 수행 \n",
    "# cross_val_score 는 기본적으로 \n",
    "# kfold 를 Stratified KFold 써서 잘 섞어 주고 머신러닝 돌릴 데이터가 회귀(그냥 kfold)인지, 분류(stratified kfold)인지 알아서 적합한 방식을 \n",
    "# 적용해주므로 kfold를 굳이 쓸 필요 없다\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# 결정 트리 분류기\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "\n",
    "# cross_val_score를 이용한 교차 검증 수행, cv=5\n",
    "scores = cross_val_score(dt_clf, X_titanic_df, y_titanic_df, cv=5)\n",
    "\n",
    "# 평균 정확도 계산\n",
    "mean_accuracy = np.mean(scores)\n",
    "\n",
    "print(f'결정 트리 cross_val_score 검증의 평균 정확도: {mean_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 하이퍼 파라미터: {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "\n",
      "찾아낸 최적값으로 DecisionTreeClassifier 정확도: 0.8715\n"
     ]
    }
   ],
   "source": [
    "# - 4. GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행.\n",
    "#   - parameters = {'max_depth':[2,3,5,10], 'min_samples_split':[2,3,5], 'min_samples_leaf':[1,5,8]}\n",
    "#   - dt_clf, scoring='accuracy', cv=5 적용\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# GridSearchCV에 사용할 하이퍼 파라미터 그리드 설정\n",
    "parameters = {\n",
    "    'max_depth': [2, 3, 5, 10],    \n",
    "    'min_samples_leaf': [1, 5, 8],\n",
    "    'min_samples_split': [2, 3, 5]\n",
    "}\n",
    "\n",
    "# DecisionTreeClassifier 객체 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "\n",
    "# GridSearchCV 객체 생성 및 학습\n",
    "grid_dtree = GridSearchCV(dt_clf, param_grid=parameters, scoring='accuracy', cv=5)\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# 최적 하이퍼 파라미터 출력 및 최적 모델 가져오기\n",
    "print('GridSearchCV 최적 하이퍼 파라미터:', grid_dtree.best_params_)\n",
    "print()\n",
    "\n",
    "best_dtree = grid_dtree.best_estimator_\n",
    "\n",
    "# 최적 모델로 예측 및 평가 수행\n",
    "pred = best_dtree.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "\n",
    "print('찾아낸 최적값으로 DecisionTreeClassifier 정확도: {0:.4f}'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "찾아낸 최적 값으로 dt 정확도: 0.8715\n",
      "찾아낸 최적 값으로 dt 정밀도: 0.8393\n",
      "찾아낸 최적 값으로 dt 재현율: 0.7705\n"
     ]
    }
   ],
   "source": [
    "#하는 김에 정확도 최적일 때 정밀도 재현율 확인해보기\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# 최적 하이퍼파라미터로 결정 트리 모델 생성\n",
    "dt_clf = DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, min_samples_split=2, random_state=11)\n",
    "\n",
    "# 모델 학습\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터셋으로 예측\n",
    "pred = dt_clf.predict(X_test)\n",
    "\n",
    "# 정확도, 정밀도, 재현율 평가\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred, pos_label=1)   #pos_label=1 은 생존한걸 양성으로 지정해서 오류가 나지 않게 설정\n",
    "recall = recall_score(y_test, pred, pos_label=1)\n",
    "\n",
    "\n",
    "print(f'찾아낸 최적 값으로 dt 정확도: {accuracy:.4f}')\n",
    "print(f'찾아낸 최적 값으로 dt 정밀도: {precision:.4f}')\n",
    "print(f'찾아낸 최적 값으로 dt 재현율: {recall:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
